{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ae3c42-7dd2-49bf-b1bb-26177c3fcdb7",
   "metadata": {},
   "source": [
    "# Keras CNN Training (cat & dog classification)\n",
    "based on https://www.youtube.com/watch?v=qFJeN9V1ZsI&t=1608s  (DeepLizard tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99fa8c-0fef-431d-9302-d3e370af41a1",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a49782e-5f7d-429e-a26a-a26b6ddd28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f727a859-a9f8-456b-81bd-bb98df8f0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb250d7-6cf9-4e83-8b09-79ba45be02dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs len=1000\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "all_cats = glob.glob('data/cats_vs_dogs/all/cats/cat.2???.jpg')\n",
    "print(f'cats len={len(all_cats)}')\n",
    "all_cats.sort()\n",
    "for file in all_cats :\n",
    "    shutil.copy(file, 'data/cats_vs_dogs/train/cats/')\n",
    "\n",
    "all_dogs = glob.glob('data/cats_vs_dogs/all/dogs/dog.2???.jpg')\n",
    "print(f'dogs len={len(all_dogs)}')\n",
    "all_dogs.sort()\n",
    "for file in all_dogs :\n",
    "    shutil.copy(file, 'data/cats_vs_dogs/train/dogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "000e1644-1220-4867-aeb4-886efdf0ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid cats len=500\n",
      "valid dogs len=500\n"
     ]
    }
   ],
   "source": [
    "# prepare validation data\n",
    "all_cats = glob.glob('data/cats_vs_dogs/all/cats/cat.1???.jpg')[:500]\n",
    "print(f'valid cats len={len(all_cats)}')\n",
    "all_cats.sort()\n",
    "for file in all_cats :\n",
    "    shutil.copy(file, 'data/cats_vs_dogs/valid/cats/')\n",
    "\n",
    "all_dogs = glob.glob('data/cats_vs_dogs/all/dogs/dog.1???.jpg')[:500]\n",
    "print(f'valid dogs len={len(all_dogs)}')\n",
    "all_dogs.sort()\n",
    "for file in all_dogs :\n",
    "    shutil.copy(file, 'data/cats_vs_dogs/valid/dogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d09405-dcbf-438a-a334-882c5aa63f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/cats_vs_dogs/train'\n",
    "valid_path = 'data/cats_vs_dogs/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939f5697-ab29-49f4-b9f4-9b39ee223018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cats', 'dogs'], batch_size=20)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cats', 'dogs'], batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ac0e3-bdf6-4108-90c9-20238f09b163",
   "metadata": {},
   "source": [
    "## Build and Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fa97a7-bbef-4878-8649-df8b0ca80e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 20:13:13.421435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 20:13:13.464855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64\n",
      "2022-03-22 20:13:13.464871: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-22 20:13:13.465556: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),    \n",
    "    Flatten(),\n",
    "    Dense(activation='softmax', units='2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c98f9ec-e278-4db7-894e-036598b9fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 401410    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d11b7f-08fa-46aa-900a-bf529e28c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c00c03e-7667-4e2b-8fe6-17b857bfe1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 42s - loss: 18.4284 - accuracy: 0.5665 - val_loss: 3.3658 - val_accuracy: 0.5700 - 42s/epoch - 417ms/step\n",
      "Epoch 2/5\n",
      "100/100 - 44s - loss: 1.2436 - accuracy: 0.7460 - val_loss: 2.3320 - val_accuracy: 0.6200 - 44s/epoch - 441ms/step\n",
      "Epoch 3/5\n",
      "100/100 - 42s - loss: 0.4316 - accuracy: 0.8700 - val_loss: 1.5568 - val_accuracy: 0.6750 - 42s/epoch - 423ms/step\n",
      "Epoch 4/5\n",
      "100/100 - 45s - loss: 0.0870 - accuracy: 0.9690 - val_loss: 1.5809 - val_accuracy: 0.6580 - 45s/epoch - 455ms/step\n",
      "Epoch 5/5\n",
      "100/100 - 44s - loss: 0.0378 - accuracy: 0.9870 - val_loss: 1.5957 - val_accuracy: 0.6740 - 44s/epoch - 442ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcf02e89d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04493704-a5ec-4ba6-99e3-5f8df41a2a62",
   "metadata": {},
   "source": [
    "Train accuracy = 0.98, whereas validation accuracy = 0.67 - this means we have huge overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeab9ba-c52c-4e7d-a6c2-2542a9ff68a0",
   "metadata": {},
   "source": [
    "## Prediction and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec0fc-bfce-44d5-8977-b521433c0ffd",
   "metadata": {},
   "source": [
    "Validation data set will be used as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67bf7f3-c730-42b1-9ac4-12556ad02483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - 4s - 4s/epoch - 75ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=valid_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d31be4-0b44-4b7d-b713-f40f81630f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9616110e-01, 3.8388404e-03],\n",
       "       [9.9999750e-01, 2.5235654e-06],\n",
       "       [1.5042346e-03, 9.9849582e-01],\n",
       "       [2.8569287e-08, 1.0000000e+00],\n",
       "       [1.3321526e-06, 9.9999869e-01],\n",
       "       [9.5847613e-01, 4.1523829e-02],\n",
       "       [8.6026013e-01, 1.3973993e-01],\n",
       "       [9.9437863e-01, 5.6213741e-03],\n",
       "       [6.5761262e-01, 3.4238738e-01],\n",
       "       [5.7136308e-04, 9.9942857e-01]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eada7385-9b54-4563-8282-f9813307f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions = np.round(predictions)\n",
    "print(rounded_predictions.shape)\n",
    "rounded_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba452d63-0675-4d81-a7e2-dedaff481e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = np.argmax(rounded_predictions, axis=1)\n",
    "predicted_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5646d36-626e-45da-b61e-3fef24f8afda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_batches.classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f533bcb-3cac-4173-9b8b-4670e60b8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eba41884-bc5d-4c56-a61b-062ca5e55329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdc16de0fa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=valid_batches.classes, y_pred=predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38545a23-34ea-437a-bcdc-86ba11cb7b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
