{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ca5727-b256-4fcf-8821-039f682f845c",
   "metadata": {},
   "source": [
    "# Pytorch - autograd package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d97162-0a73-41b5-8fc6-f9b5c1dd9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf185a7-d89a-4b06-95a5-72e0a683295b",
   "metadata": {},
   "source": [
    "### auto_grad enabled - the basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77689214-a197-4608-9728-df16417dedd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.], requires_grad=True),\n",
       " tensor([1., 1., 1., 1., 1.], requires_grad=True))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # this flag enables automatic gradient calculation with respect to x when calculatig some functions using x\n",
    "y = torch.ones(5, requires_grad=True)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a803476a-5cfe-49b3-8111-f48a93b2b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>),\n",
       " tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x * 2 \n",
    "y2 = y * 2\n",
    "x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "174e9341-7da5-4a17-bcde-c294593853d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10., grad_fn=<SumBackward0>), tensor(2., grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to calculate the gradient dy/dx we must use backward() method\n",
    "# but this method can be only executed on a scalar -> hence the exaples below\n",
    "sum = x2.sum()\n",
    "avg = y2.mean()\n",
    "\n",
    "sum, avg \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52874c42-0067-4d09-816f-adbab556623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10., grad_fn=<SumBackward0>),\n",
       " tensor([2., 2., 2., 2., 2.]),\n",
       " tensor(2., grad_fn=<MeanBackward0>),\n",
       " tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the above tensors have grad_function present (we see they have), what is needed to to run this backward() method on them\n",
    "sum.backward() \n",
    "avg.backward()\n",
    "sum, x.grad, avg, y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b9ad85a-3678-4425-94cb-60279124eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling backward() method again will produce an error\n",
    "# sum.backward() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ecb36-3f63-466e-9471-08203cfcd3ac",
   "metadata": {},
   "source": [
    "### Calling backward on a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa7496ee-f939-42a9-9655-3b1db28cc1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>),\n",
       " tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.ones(5, requires_grad=True) \n",
    "y = torch.ones(5, requires_grad=True)\n",
    "x2 = x * 2 \n",
    "y2 = y * 2\n",
    "x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65fd4a2b-8637-4d20-9a66-688c391b3ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03, 1.0000e+04])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = torch.tensor([1, 10, 100, 1000, 10000], dtype=torch.float32)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13be1314-0806-4644-a485-3cd22fe8b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03, 2.0000e+04]),\n",
       " tensor([2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03, 2.0000e+04]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.backward(base) # TODO how it works?\n",
    "y2.backward(base)\n",
    "\n",
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b998c-da81-431c-8b31-2a167306d9c8",
   "metadata": {},
   "source": [
    "### Gradient for multiple operations (chain rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "007054a5-1fc0-49ac-9b26-afe4d6f503ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, requires_grad=True) \n",
    "base = torch.ones(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da4efd7b-8b56-4bf6-ba67-af42d4e8bb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.])\n",
      "tensor([4., 4., 4.])\n",
      "tensor([6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x2 = x * 2\n",
    "    x2.backward(base)\n",
    "    print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21a75fbb-08ee-432b-be93-34a79d4a3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the gradient cumulates all operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5c64e-bb22-4441-89b4-f2f725ba796f",
   "metadata": {},
   "source": [
    "### Zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b97a5cf-c81c-4a40-bba8-8d380289b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, requires_grad=True) \n",
    "base = torch.ones(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2278ea09-eed6-4265-b0d8-d74d1651244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.])\n",
      "tensor([2., 2., 2.])\n",
      "tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x2 = x * 2\n",
    "    x2.backward(base)\n",
    "    print(x.grad)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d648040-5e95-499f-8a16-da0e860f70ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1bff31c-8b3e-4b49-9642-3f138ebbf362",
   "metadata": {},
   "source": [
    "### Tuning off gradinet calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58f27c22-ccd9-45cc-92cf-64cd1852ef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 1\n",
    "x = torch.ones(5, requires_grad=True) \n",
    "x.requires_grad_(False)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdf68e4c-045b-4717-a2f1-2608cefe1164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 2\n",
    "x = torch.ones(5, requires_grad=True) \n",
    "y = x.detach() # this is used to detach a tensor from the current computational graph. It returns a new tensor that doesn't require a gradient.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9203ce-589a-43ad-a414-1934d83da876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae85ed11-2177-4ed6-8286-dd34e0f862b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # context manager that disables gradient calculations\n",
    "    y = x * 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b66a1-ba15-4c8d-b42c-130c0f79f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aba65d-b70f-4ab7-a784-8bbeca9847d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16355054-7347-4b3f-88ac-8036a582906c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
