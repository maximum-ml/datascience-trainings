{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa002e4e-b05f-43b5-bd43-5351e427d1f5",
   "metadata": {},
   "source": [
    "# Pytorch - Back Propagation & Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012555f6-8b1c-497c-a7ff-8775a9b47c34",
   "metadata": {},
   "source": [
    "### Back propagation with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add18c7a-222c-4a7a-9a58-27fe5b0cdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc54d42-6b61-4907-9b91-6085889c022f",
   "metadata": {},
   "source": [
    "### Solution 1 - Fully manual calculations with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b669e30-2d93-4579-ab50-6184c71acdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([10, 20, 30, 40, 50], dtype=np.float32)\n",
    "Y = np.array([20, 40, 60, 80, 100], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c334b593-849a-43ba-a265-0fcbe6fc6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 0.0\n",
    "learning_rate = 0.0003 # this must be adjusted (for example 0.001 won't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451d0b7-0947-4762-830b-3bfe7cbcd119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f0f6c50-7d25-4812-a53a-4ceb656ad2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return W * x\n",
    "\n",
    "# MSE\n",
    "def loss(y_actual, y_predicted):\n",
    "    return ((y_predicted - y_actual) ** 2).mean()\n",
    "\n",
    "# dLoss/dW\n",
    "def gradient(x, y_actual, y_predicted):\n",
    "    return np.dot(-x * 2 / 5, y_predicted - y_actual).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c91a78e1-41f0-4c99-b57a-313d7cb2a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=4400.00000, W=0.00000, grad=-4400.00000\n",
      "epoch=1, loss=508.63995, W=1.32000, grad=-1496.00000\n",
      "epoch=2, loss=58.79878, W=1.76880, grad=-508.63995\n",
      "epoch=3, loss=6.79714, W=1.92139, grad=-172.93767\n",
      "epoch=4, loss=0.78575, W=1.97327, grad=-58.79877\n",
      "epoch=5, loss=0.09083, W=1.99091, grad=-19.99150\n",
      "epoch=6, loss=0.01050, W=1.99691, grad=-6.79723\n",
      "epoch=7, loss=0.00121, W=1.99895, grad=-2.31105\n",
      "epoch=8, loss=0.00014, W=1.99964, grad=-0.78572\n",
      "epoch=9, loss=0.00002, W=1.99988, grad=-0.26723\n",
      "epoch=10, loss=0.00000, W=1.99996, grad=-0.09064\n",
      "epoch=11, loss=0.00000, W=1.99999, grad=-0.03098\n",
      "epoch=12, loss=0.00000, W=2.00000, grad=-0.01048\n",
      "epoch=13, loss=0.00000, W=2.00000, grad=-0.00372\n",
      "epoch=14, loss=0.00000, W=2.00000, grad=-0.00096\n",
      "epoch=15, loss=0.00000, W=2.00000, grad=-0.00056\n",
      "epoch=16, loss=0.00000, W=2.00000, grad=-0.00036\n",
      "epoch=17, loss=0.00000, W=2.00000, grad=0.00000\n",
      "epoch=18, loss=0.00000, W=2.00000, grad=0.00000\n",
      "epoch=19, loss=0.00000, W=2.00000, grad=0.00000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # prediction\n",
    "    y = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, Y)\n",
    "    \n",
    "    # grad\n",
    "    grad = gradient(X, y, Y)\n",
    "     \n",
    "    if (epoch % 1 == 0):\n",
    "        print(f'epoch={epoch}, loss={l:.5f}, W={W:.5f}, grad={grad:.5f}')\n",
    "    \n",
    "    # weight update\n",
    "    W -= learning_rate * grad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ca3ca-08e1-48a6-b1fe-7b09d9f09ae2",
   "metadata": {},
   "source": [
    "### Solution 2 - using Pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f699953e-5d99-4689-84fc-7a5f4f594619",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([10, 20, 30, 40, 50], dtype=torch.float32) # input vector\n",
    "Y = torch.tensor([20, 40, 60, 80, 100], dtype=torch.float32) # output vector\n",
    "W = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "learning_rate = torch.tensor(0.0003, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42a8a5ca-5114-41a3-8855-c05a22adffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use previously defined functions i.e. forward() and loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1026e0a-94c2-4289-869e-d1e604cc280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=4400.00000, W=0.00000, grad=-4400.00000\n",
      "epoch=1, loss=508.63995, W=1.32000, grad=-1495.99988\n",
      "epoch=2, loss=58.79878, W=1.76880, grad=-508.63998\n",
      "epoch=3, loss=6.79714, W=1.92139, grad=-172.93767\n",
      "epoch=4, loss=0.78575, W=1.97327, grad=-58.79877\n",
      "epoch=5, loss=0.09083, W=1.99091, grad=-19.99150\n",
      "epoch=6, loss=0.01050, W=1.99691, grad=-6.79723\n",
      "epoch=7, loss=0.00121, W=1.99895, grad=-2.31105\n",
      "epoch=8, loss=0.00014, W=1.99964, grad=-0.78572\n",
      "epoch=9, loss=0.00002, W=1.99988, grad=-0.26723\n",
      "epoch=10, loss=0.00000, W=1.99996, grad=-0.09064\n",
      "epoch=11, loss=0.00000, W=1.99999, grad=-0.03098\n",
      "epoch=12, loss=0.00000, W=2.00000, grad=-0.01048\n",
      "epoch=13, loss=0.00000, W=2.00000, grad=-0.00372\n",
      "epoch=14, loss=0.00000, W=2.00000, grad=-0.00132\n",
      "epoch=15, loss=0.00000, W=2.00000, grad=-0.00056\n",
      "epoch=16, loss=0.00000, W=2.00000, grad=-0.00036\n",
      "epoch=17, loss=0.00000, W=2.00000, grad=0.00000\n",
      "epoch=18, loss=0.00000, W=2.00000, grad=0.00000\n",
      "epoch=19, loss=0.00000, W=2.00000, grad=0.00000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # prediction\n",
    "    y = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, Y)\n",
    "    \n",
    "    # grad\n",
    "    l.backward()\n",
    "    grad = W.grad\n",
    "     \n",
    "    if (epoch % 1 == 0):\n",
    "        print(f'epoch={epoch}, loss={l:.5f}, W={W:.5f}, grad={grad:.5f}')\n",
    "    \n",
    "    # weight update ... but outside computation tree (to not intefere with gradient)\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * grad \n",
    "    \n",
    "    # this is important to not accumulated gradient from previous iterations\n",
    "    W.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b2c3e-f1bb-4839-a085-eef7dc91677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the grad computation is exacly the same as by the manual solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550d9d0-e78b-4a35-a705-a6150e92f676",
   "metadata": {},
   "source": [
    "### Solution 3 - using Pytorch Neural Network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e61fb1-3a64-4a82-a4da-a300a4611bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63551daa-7f4f-4e23-8d39-88afcb322127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[10], [20], [30], [40], [50]], dtype=torch.float32) # input vector [nb_samples * nb_features] -> here 5 * 1\n",
    "Y = torch.tensor([[20], [40], [60], [80], [100]], dtype=torch.float32) # output vector [nb_samples * nb_features] -> here 5 * 1\n",
    "\n",
    "nb_samples, nb_features = X.shape\n",
    "nb_samples, nb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1521b38f-2f9e-4a4f-9e89-93a2c3555a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =0.0003\n",
    "\n",
    "input_size = nb_features\n",
    "output_size = nb_features\n",
    "\n",
    "# we don't need to use weights vector, but instead we use Linear model\n",
    "model = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bea6dd9-ebaa-4843-ac92-9c9b1d899c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[54.5764]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial prediction\n",
    "X_test = torch.tensor([[60]], dtype=torch.float32)\n",
    "Y_test_pred = model(X_test)\n",
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc7abebd-b9af-4e59-9d02-24fab8bd732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=1297.12988, W=0.90255, b=0.42367\n",
      "epoch=5, loss=0.06371, W=1.98275, b=0.45289\n",
      "epoch=10, loss=0.03727, W=1.98763, b=0.45278\n",
      "epoch=15, loss=0.03723, W=1.98766, b=0.45253\n",
      "epoch=20, loss=0.03719, W=1.98766, b=0.45228\n",
      "epoch=25, loss=0.03715, W=1.98767, b=0.45204\n",
      "epoch=30, loss=0.03711, W=1.98768, b=0.45179\n",
      "epoch=35, loss=0.03707, W=1.98768, b=0.45154\n",
      "epoch=40, loss=0.03703, W=1.98769, b=0.45130\n",
      "epoch=45, loss=0.03699, W=1.98770, b=0.45105\n",
      "epoch=50, loss=0.03695, W=1.98770, b=0.45081\n",
      "epoch=55, loss=0.03691, W=1.98771, b=0.45056\n",
      "epoch=60, loss=0.03687, W=1.98772, b=0.45032\n",
      "epoch=65, loss=0.03683, W=1.98772, b=0.45007\n",
      "epoch=70, loss=0.03679, W=1.98773, b=0.44982\n",
      "epoch=75, loss=0.03675, W=1.98774, b=0.44958\n",
      "epoch=80, loss=0.03671, W=1.98774, b=0.44933\n",
      "epoch=85, loss=0.03667, W=1.98775, b=0.44909\n",
      "epoch=90, loss=0.03663, W=1.98776, b=0.44885\n",
      "epoch=95, loss=0.03659, W=1.98776, b=0.44860\n",
      "epoch=99, loss=0.03656, W=1.98777, b=0.44840\n"
     ]
    }
   ],
   "source": [
    "# Training (hmm ? )\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # prediction (forward pass)\n",
    "    y = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss_function(Y, y)\n",
    "    \n",
    "    # gradients (backward pass)\n",
    "    grad = l.backward()\n",
    "    \n",
    "    if (epoch % 5 == 0 or epoch + 1 == max_epochs):\n",
    "        w = model.weight.item()\n",
    "        b = model.bias.item()\n",
    "        print(f'epoch={epoch}, loss={l:.5f}, W={w:.5f}, b={b:.5f}')\n",
    "    \n",
    "    # weights update in the model\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc662b90-296f-4f15-b5f4-a50206349e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[119.7146]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction after training:\n",
    "X_test = torch.tensor([[60]], dtype=torch.float32)\n",
    "Y_test_pred = model(X_test)\n",
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38acef-ad8a-441e-ad8d-cd9ff82a7bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
